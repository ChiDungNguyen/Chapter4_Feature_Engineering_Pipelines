{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: \n",
    "# Cải thiện khả năng dự báo của mô hình bằng Feature Engineering\n",
    "\n",
    "Như đã đề cập trong chương 1, Feature Engineering (FE) được hiểu như là việc biến đổi - chuyển hóa dữ liệu nguyên bản (Original Feature) thành Feature mới sao cho khả năng dự báo và phân loại của mô hình ML tăng lên. FE có thể là kĩ thuật đơn giản chuyển hóa biến định tính (Categorical) về biến Binary 0 - 1 vì rằng hầu hết các mô hình ML được xây dựng trong Python không chấp nhận Feature là biến định tính. FE không chỉ là biến đổi - chuyển hóa các features ban đầu thành các features mới mà còn có thể là việc tìm ra một feature mới (bằng một sự kết hợp - biến đổi nào đó từ các features đã có) để nâng cao khả năng phân loại - dựa báo của mô hình. \n",
    "\n",
    "Chương này hướng vào các nội dung sau: \n",
    "\n",
    "- Giới thiệu về FE cho các mô hình ML. Để minh họa thì kĩ thuật chuẩn hóa 0 - 1 được sử dụng với mô hình KNN. \n",
    "- Tinh chỉnh tham số kết hợp với FE và Pipelines. \n",
    "- So sánh chất lượng dự báo - phân loại của mô hình khi không và có sử dụng FE. \n",
    "\n",
    "# 4.1 Feature Engineering \n",
    "\n",
    "Trong chương 1 chúng ta đã thấy với K = 1 và sử dụng dữ liệu nguyên bản thì Accuracy = 57.6%. Mức độ chính xác khi phân loại như vậy là không đủ tốt để sử dụng theo các tiêu chí đánh giá như đã trình bày trong chương 3. Để nâng cao khả năng phân loại - dự báo của mô hình chúng ta có thể tìm tham số tối ưu thông qua quá trình tinh chỉnh tham số đã được trình bày trong chương 2. \n",
    "\n",
    "Tuy nhiên với FE chúng ta có thể cái thiện chất lượng dự báo - phân loại của mô hình một cách nhanh chóng. Để minh họa chúng ta trở lại với mô hình KNN với K = 1 và so sánh Accuracy trong hai tình huống: sử dụng và không sử dụng FE khi huấn luyện mô hình. Bằng kĩ thuật chuẩn hóa 0 - 1 đơn giản chúng ta có thể tăng Accuracy lên 63.55%. Trước hết thực hiện chuẩn bị dữ liệu: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================\n",
    "#  Chuẩn bị dữ liệu cho huấn luyện KNN\n",
    "#========================================\n",
    "\n",
    "import pandas as pd\n",
    "df_bank = pd.read_csv(\"C:/Users/Zbook/Desktop/DataMining/dmba/UniversalBank.csv\")\n",
    "my_df_binary = df_bank.drop([\"ZIP Code\", \"ID\"], axis=1)\n",
    "Y = my_df_binary[\"CreditCard\"]\n",
    "X = my_df_binary.drop(\"CreditCard\", 1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4, random_state = 29, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy nếu sử dụng dữ liệu nguyên bản: 0.576\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện KNN với K = 1: \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn1.fit(X_train, y_train)\n",
    "\n",
    "# Tính Accuracy và hiển thị kết quả: \n",
    "accuracy_noneScaled = knn1.score(X_test, y_test)\n",
    "print(\"Accuracy nếu sử dụng dữ liệu nguyên bản:\", accuracy_noneScaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN là một thuật toán dựa vào khoảng cách và do vậy rất nhạy với thước đo được sử dụng cho Features. Kinh nghiệm được đo theo đơn vị là năm và nó là một con số khá bé (nằm đâu đó từ 0 đến 50 là cùng) so với thu nhập có đơn vị, ví dụ, là VND và con số thu nhập có thể từ vài ba triệu cho đến hàng trăm triệu. Do vậy chúng ta cần chuẩn hóa tất cả các thước đo này về *cùng một thước đo*. \n",
    "\n",
    "Bằng sử dụng chuẩn hóa 0 - 1 cho các features chúng ta có thể cải thiện đáng kể chất lượng của mô hình. Chú ý rằng khi huấn luyện thì chúng ta phải huấn luyện trên dữ liệu train đã được chuẩn hóa còn dự báo chúng ta phải thực hiện trên dữ liệu test. Scikit-Learn hỗ trợ nhiều kĩ thuật FE cho features chứ không chỉ kĩ thuật chuẩn hóa 0 - 1. Dưới đây là Python Codes thực hiện kĩ thuật chuẩn hóa này: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hàm MinMaxScaler() từ Sciki-Learn cho chuẩn hóa 0 - 1: \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Kích hoạt hàm chuẩn hóa: \n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Chuẩn hóa 0 - 1 cho train data: \n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Huấn luyện KNN trên train data đã được chuẩn hóa: \n",
    "knn_scaled = knn1.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để thực hiện dự báo chúng ta sử dụng mô hình đối với dữ liệu test data chuẩn hóa chứ không phải nguyên bản: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy nếu sử dụng dữ liệu chuẩn hóa: 0.6355\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hóa test data: \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Thực hiện dự báo trên test data đã chuẩn hóa: \n",
    "accuracy_scaled = knn_scaled.score(X_test_scaled, y_test)\n",
    "\n",
    "# Accuracy của mô hình KNN: \n",
    "print(\"Accuracy nếu sử dụng dữ liệu chuẩn hóa:\", accuracy_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy chỉ với kĩ thuật FE đơn giản là chuẩn hóa 0 - 1 thì chúng ta đã có thể cải thiện chất lượng dự báo của mô hình lên khoảng 10.32%: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.329861111111116"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*(accuracy_scaled / accuracy_noneScaled - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy với chỉ cùng một giá trị của tham số K chúng ta có thể nâng cao chất lượng phân loại - dự báo của mô hình lên đáng kể. Nhưng trong thực tế, FE chỉ mới là một phần của quá trình tìm kiếm - xây dựng một mô hình ML đủ tốt/tốt hơn nữa. Chúng ta phải kết hợp FE với quá trình tinh chỉnh tham số cho mô hình như mục 4.2 dưới đây. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Feature Engineering kết hợp Grid Search \n",
    "\n",
    "Tìm kiếm tham số tối ưu thông qua quá trình tinh chỉnh tham số mô hình là bước quan trọng của việc xây dựng mô hình ML trước khi nghĩ đến việc triển khai và ứng dụng nó. Chúng ta có thể kết hợp FE và tinh chỉnh tham số cho mô hình bằng Grid Search. Dưới đây là Python Codes cho tinh chỉnh tham số của mô hình SVM kết hợp với FE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trung bình cao nhất từ Cross-Validation: 0.747\n",
      "Accuracy trên test data (đã chuẩn hóa):  0.7415\n"
     ]
    }
   ],
   "source": [
    "# Load hàm SVC + GridSearchCV từ thư viện Scikit-Learn: \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Thiết lập Grid Search cho tinh chỉnh: \n",
    "param_grid = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100], \"gamma\": [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Tinh chỉnh mô hình với 5 Fold Cross-Validation và huấn luyện luôn trên train đã được chuẩn hóa 0 - 1: \n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Accuracy trung bình cao nhất (cho 5 lần chạy mẫu) trên train data chuẩn hóa: \n",
    "best_Accuracy_fromCrossValidation = grid.best_score_\n",
    "\n",
    "# Accuracy trên test data đã được chuẩn hóa: \n",
    "Accuracy_onTestData = grid.score(X_test_scaled, y_test)\n",
    "\n",
    "# Hiển thị các kết quả: \n",
    "print(\"Accuracy trung bình cao nhất từ Cross-Validation:\", best_Accuracy_fromCrossValidation)\n",
    "print(\"Accuracy trên test data (đã chuẩn hóa): \", Accuracy_onTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể chỉ ra tham số tối ưu mà khi huấn luyện SVM thì có Accuracy = 0.745 trên test data chuẩn hóa: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters tối ưu:  {'C': 100, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters tối ưu: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đương nhiên kết quả Accuracy = 0.7415 có thể tìm lại bằng cách huyến luyện trực tiếp KNN với cặp tham số này rồi tính toán lại Accuracy cho test data chuẩn hóa: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trên test data (đã chuẩn hóa):  0.7415\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện lại SVM với cặp tham số tối ưu gamma + C: \n",
    "svm_bestParameters = SVC(**grid.best_params_)\n",
    "\n",
    "# Huấn luyện SVM và tính Accuracy: \n",
    "acc_bestParameters = svm_bestParameters.fit(X_train_scaled, y_train).score(X_test_scaled, y_test)\n",
    "\n",
    "# Hiển thik kết quả: \n",
    "print(\"Accuracy trên test data (đã chuẩn hóa): \", acc_bestParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 FE, Grid Search và Pipelines\n",
    "\n",
    "Trong thực tế thì chúng ta có thể thực hiện một chuỗi các kĩ thuật biến đổi - chuyển hóa features nguyên bản thành features mới chứ không chỉ thực hiện chuẩn hóa 0-1 như đã thấy. Mặt khác, như đã thấy để xây dựng một mô hình ML với chuẩn hóa 0-1 chúng ta cần có thể phải chuẩn bị trước train và test data đã được chuẩn hóa trước khi xây dựng và đánh giá mô hình. Rất may mắn là Scikit-Learn có thể hỗ trợ cho khâu FE, huấn luyện và đánh giá mô hình theo một cách thức trình bày ngắn gọn và tiện lợi hơn rất nhiều bằng một \"thủ tục\" gọi là *Pipelines* (tôi chưa biết dịch là gì dù rằng nó trùng tên với bản hit Pipeline của ban nhạc The Ventures và tôi đã nghe từ lâu). Lợi ích của Pipelines là: \n",
    "\n",
    "- Gói gọn quá trình từ FE, tinh chỉnh, huấn luyện và đánh giá bằng một quy trình kín từ A-Z. \n",
    "- Trình bày ngắn gọn, tiện lợi cho việc huấn luyện, so sánh - lựa chọn nhiều mô hình ML khác nhau. \n",
    "\n",
    "Để minh họa thủ tục Pipelines chúng ta trở lại với KNN khi K = 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy với FE là chuẩn hóa 0-1 cho test data: 0.6355\n"
     ]
    }
   ],
   "source": [
    "# Load hàm Pipeline: \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Thiết lập thông số cho huấn luyện và chuẩn hóa 0 - 1: \n",
    "pipe_knn = Pipeline([(\"scaler\", MinMaxScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=1))])\n",
    "\n",
    "# Huấn luyện KNN: \n",
    "pipe_knn.fit(X_train, y_train)\n",
    "\n",
    "# Tính Accuracy: \n",
    "acc = pipe_knn.score(X_test, y_test)\n",
    "\n",
    "# In Accuracy: \n",
    "print(\"Accuracy với FE là chuẩn hóa 0-1 cho test data:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng Pipelines cho FE + tinh chỉnh tham số theo cách tiếp cận Grid Search được thực hiện như Python Codes dưới đây. Để minh họa thì hai mô hình ML được chọn là KNN và SVM:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy cao nhất từ Cross-Validation: 0.7413333333333333\n",
      "Accuracy cho Test Data:  0.741\n",
      "Parameters tốt nhất:  {'KNN__n_neighbors': 29}\n"
     ]
    }
   ],
   "source": [
    "#==============================================\n",
    "# Pipelines cho FE + tinh chỉnh tham số, KNN\n",
    "#==============================================\n",
    "\n",
    "# Thiết lập thông số cho huấn luyện và chuẩn hóa 0 - 1: \n",
    "pipe_knn = Pipeline([(\"scaler\", MinMaxScaler()), (\"KNN\", KNeighborsClassifier())])\n",
    "\n",
    "# Định nghĩa các ứng viên tiềm năng cho tham số: \n",
    "param_grid_knn = {\"KNN__n_neighbors\": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]}\n",
    "\n",
    "# Thiết lập môi trường tinh chỉnh: \n",
    "grid_search_knn = GridSearchCV(pipe_knn, param_grid_knn, cv=5)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "print(\"Accuracy cao nhất từ Cross-Validation:\", grid_search_knn.best_score_)\n",
    "print(\"Accuracy cho Test Data: \", grid_search_knn.score(X_test, y_test))\n",
    "print(\"Parameters tốt nhất: \", grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một lần nữa giá trị Accuracy = 0.741 có thể được tính toán một cách trực tiếp như sau: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tương ứng với tham số tối ưu, KNN: 0.741\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện lại KNN với tham số tối ưu tìm được: \n",
    "best_knn = KNeighborsClassifier(n_neighbors=29)\n",
    "\n",
    "# Huấn luyện và tính Accuracy: \n",
    "acc_best_knn = best_knn.fit(X_train_scaled, y_train).score(X_test_scaled, y_test)\n",
    "\n",
    "# In giá trị Accuracy: \n",
    "print(\"Accuracy tương ứng với tham số tối ưu, KNN:\", acc_best_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự là sử dụng thủ tục Pipelines cho SVM - một mô hình có tham số tinh chỉnh là gamma và C: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy cao nhất từ Cross-Validation: 0.747\n",
      "Accuracy cho Test Data:  0.7415\n",
      "Parameters tốt nhất:  {'SVM__C': 100, 'SVM__gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#==============================================\n",
    "# Pipelines cho FE + tinh chỉnh tham số, SVM\n",
    "#==============================================\n",
    "\n",
    "# Chỉ thị cụ thể kĩ thuật FE và các ứng viên tiềm năng cho tham số: \n",
    "pipe_svm = Pipeline([(\"scaler\", MinMaxScaler()), (\"SVM\", SVC())])\n",
    "param_grid_svm = {\"SVM__C\": [10, 100], \"SVM__gamma\": [0.01, 0.1]}\n",
    "\n",
    "# Load GridSearchCV: \n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Tinh chỉnh (tìm tham số tối ưu) và huấn luyện: \n",
    "grid_search_svm = GridSearchCV(pipe_svm, param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Kết quả Accuracy trên test data và một số kết quả khác: \n",
    "print(\"Accuracy cao nhất từ Cross-Validation:\", grid_search_svm.best_score_)\n",
    "print(\"Accuracy cho Test Data: \", grid_search_svm.score(X_test, y_test))\n",
    "print(\"Parameters tốt nhất: \", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Tóm tắt chương\n",
    "\n",
    "Chương này chỉ ra tác động của FE lên chất lượng phân loại - dự báo của các mô hình ML và sử dụng FE như là một \"kĩ thuật\" nâng cao chất lượng phân loại - dự báo. Để minh họa thì kĩ thuật chuẩn hóa 0-1 được lựa chọn với các mô hình KNN và SVM. Chương này cũng trình bày khía cạnh thực hành của việc kết hợp tinh chỉnh tham số theo cách tiếp cận Grid Search và FE. Chúng ta có thể áp dụng FE hoàn toàn tương tự cho: (1) các mô hình ML khác, (2) các kĩ thuật FE khác, và (3) kết hợp nhiều kĩ thuật FE cho cùng một thuật toán ML. \n",
    "\n",
    "Còn nhiều khía cạnh tinh vi hơn của FE áp dụng cho các mô hình ML nhưng trong phạm vi là một textbook cơ bản thì những điều này khó có thể trình bày trong chương. Bạn đọc quan tâm có thể tìm đến các tài liệu khác về chủ đề này. \n",
    "\n",
    "# Tài liệu tham khảo\n",
    "\n",
    "1. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning. New York: Springer.\n",
    "2. Kuhn, M., & Johnson, K. (2013). Applied predictive modeling. New York: Springer.\n",
    "3. Müller, A. C., & Guido, S. (2016). Introduction to machine learning with Python: a guide for data scientists. O'Reilly Media, Inc.\n",
    "4. Géron, A. (2019). Hands-on machine learning with Scikit-Learn and TensorFlow: Concepts, tools, and techniques to build intelligent systems. O'Reilly Media, Inc.\n",
    "5. Shmueli, G., Bruce, P. C., Yahav, I., Patel, N. R., & Lichtendahl Jr, K. C. (2017). Data mining for business analytics: concepts, techniques, and applications in R. John Wiley & Sons. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
